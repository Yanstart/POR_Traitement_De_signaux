{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44369c27-877b-4e5e-8ce3-29bc93eed8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidéo terminée ou problème lors de la lecture de la frame.\n",
      "La vidéo avec POR a été sauvegardée localement sous le nom : video_with_por_output.avi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Noms des fichiers\n",
    "data_file = 'données POR.xlsx'\n",
    "video_file = 'Test Your Awareness.avi'\n",
    "output_file = 'video_with_por_output.avi'\n",
    "\n",
    "# 1. Chargement des données de points de regard\n",
    "def load_por_data(file_path):\n",
    "    \"\"\"\n",
    "    Charge les données de points de regard (POR) depuis un fichier Excel.\n",
    "    Normalise la colonne 'Time' pour démarrer à 0 et utilise les coordonnées de l'œil droit pour ce test.\n",
    "\n",
    "    - Elle reçoit : Le chemin vers le fichier Excel.\n",
    "    - Elle fait : Convertit la colonne 'Time' pour un démarrage à 0, par ce que je n'ai pas compris à quoi correspond le time (timestamp d'après chatgpt, surement est pris à partir d'une réference que je n'ai pas).\n",
    "    - Elle renvoie : Un DataFrame avec 'time', 'R POR X [px]', et 'R POR Y [px]'.\n",
    "    \"\"\"\n",
    "    # pd.read_excel(file_path) : Charge le fichier Excel et renvoie un DataFrame avec les données.\n",
    "    # df[['Time', 'R POR X [px]', 'R POR Y [px]']] : Sélectionne les colonnes nécessaires du DataFrame.\n",
    "    # rename(...) : Renomme les colonnes pour faciliter la manipulation.\n",
    "    # df['time'] - df['time'].iloc[0] : Normalise 'time' pour démarrer à 0.\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df[['Time', 'R POR X [px]', 'R POR Y [px]']].rename(columns={'Time': 'time', 'R POR X [px]': 'x', 'R POR Y [px]': 'y'})\n",
    "    df['time'] = df['time'] - df['time'].iloc[0]  # Normaliser le temps pour démarrer à 0\n",
    "    return df\n",
    "\n",
    "# 2. Mise à l'échelle des coordonnées par ce qu'ils sont trop grand pour être en pixel\n",
    "def scale_coordinates(por_data, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Met à l'échelle les coordonnées de points de regard pour les adapter à la résolution de la vidéo.\n",
    "    Utilise les valeurs maximales trouvées pour offrir un champ de mouvement maximal.\n",
    "\n",
    "    - Elle reçoit : Le DataFrame de points de regard et les dimensions de la vidéo.\n",
    "    - Elle fait : Normalise 'x' et 'y' en fonction des valeurs maximales observées et arrondit vers le haut.\n",
    "    - Elle renvoie : Un DataFrame avec des coordonnées mises à l'échelle.\n",
    "    \"\"\"\n",
    "    # max_x, max_y : Valeurs maximales définies pour les axes X et Y, permettant une mise à l'échelle optimale.\n",
    "    max_x, max_y = 18202624, 11357281  # Valeurs maximales pour R POR X et Y j'ai lu le fichier en python et ai recupéré la plus grande valeur de chacun des coordonnées\n",
    "    # np.ceil(...) : Applique un arrondi à l'excès après la normalisation pour éviter la perte de mouvement.\n",
    "    por_data['x'] = np.ceil((por_data['x'] / max_x) * frame_width)\n",
    "    por_data['y'] = np.ceil((por_data['y'] / max_y) * frame_height)\n",
    "    return por_data\n",
    "\n",
    "# 3. Incrustation du point de regard dans chaque frame\n",
    "def overlay_gaze_point(video_file, por_data, output_file):\n",
    "    \"\"\"\n",
    "    Parcourt chaque frame de la vidéo et y incruste le point de regard.\n",
    "\n",
    "    - Elle reçoit : Le fichier vidéo, le DataFrame de points de regard, et le nom du fichier de sortie.\n",
    "    - Elle fait : Incruste un cercle rouge dans chaque frame selon les coordonnées (x, y) de l'œil.\n",
    "    - Elle renvoie : Sauvegarde une nouvelle vidéo avec le point de regard dans chaque frame.\n",
    "    \"\"\"\n",
    "    # cv2.VideoCapture(video_file) : Ouvre le fichier vidéo pour en lire les frames.\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    # cap.get(cv2.CAP_PROP_FRAME_WIDTH) et cap.get(cv2.CAP_PROP_FRAME_HEIGHT) : Récupèrent la largeur et la hauteur de la vidéo.\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    # fps : Nombre d'images par seconde basé sur le nombre de lignes de por_data et de frames de la vidéo.\n",
    "    fps = len(por_data) / cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    # cv2.VideoWriter : Initialise la vidéo de sortie avec les dimensions et fps définis.\n",
    "    out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))\n",
    "\n",
    "    # Dernières coordonnées valides pour gérer les valeurs manquantes\n",
    "    last_x, last_y = None, None\n",
    "\n",
    "    # Itération sur chaque frame et chaque ligne de données\n",
    "    for index, row in por_data.iterrows():\n",
    "        # cap.read() : Lit une nouvelle frame de la vidéo. Renvoie un booléen 'ret' pour indiquer si la lecture est réussie, et la frame elle-même.\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Vidéo terminée ou problème lors de la lecture de la frame.\")\n",
    "            break\n",
    "\n",
    "        # Récupérer les coordonnées ou utiliser les dernières valides si manquantes\n",
    "        x, y = int(row['x']), int(row['y'])\n",
    "        # pd.isna(...) : Vérifie si les coordonnées sont NaN (valeurs manquantes)\n",
    "        if pd.isna(x) or pd.isna(y):\n",
    "            x, y = last_x, last_y\n",
    "        else:\n",
    "            last_x, last_y = x, y\n",
    "\n",
    "        # cv2.circle(frame, (x, y), 10, (0, 0, 255), -1) : Incruste un cercle rouge de rayon 10 pixels aux coordonnées (x, y) sur la frame.\n",
    "        cv2.circle(frame, (x, y), 10, (0, 0, 255), -1)\n",
    "\n",
    "        # out.write(frame) : Écrit la frame modifiée dans le fichier vidéo de sortie.\n",
    "        out.write(frame)\n",
    "\n",
    "        # cv2.imshow(...) : Affiche la frame en cours de traitement dans une fenêtre appelée 'POR Overlay'.\n",
    "        cv2.imshow('POR Overlay', frame)\n",
    "        # cv2.waitKey(1) & 0xFF == ord('q') : Attend une touche pressée. Si 'q' est pressé, arrête le processus.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Arrêt manuel par l'utilisateur.\")\n",
    "            break\n",
    "\n",
    "    # cap.release() et out.release() : Libèrent les ressources vidéo pour le fichier d'entrée et de sortie.\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    # cv2.destroyAllWindows() : Ferme toutes les fenêtres d'affichage créées par OpenCV.\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"La vidéo avec POR a été sauvegardée localement sous le nom : {output_file}\")\n",
    "\n",
    "# Exécution principale\n",
    "por_data = load_por_data(data_file)\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "frame_width, frame_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "por_data = scale_coordinates(por_data, frame_width, frame_height)\n",
    "overlay_gaze_point(video_file, por_data, output_file)\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6aebd-d66a-41c0-ba80-860ec5b6d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc03f5d-4ff9-46bb-bdc6-97f5e8be4d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

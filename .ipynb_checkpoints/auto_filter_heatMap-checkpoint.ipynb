{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8330290f-fb24-40c3-84b1-397f6c7440ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration for the eye tracking visualization.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Video paths\n",
    "        self.video_path = \"assets/Test Your Awareness.avi\"\n",
    "        self.data_path = \"assets/DataPOR.csv\"\n",
    "        self.output_path = \"assets/EyeTrackingMVP2.avi\"\n",
    "        \n",
    "        self._verify_files()\n",
    "        \n",
    "        # Resolution mapping\n",
    "        self.source_resolution = (1600, 1050)\n",
    "        \n",
    "        # DPI settings (pour conversion cm -> pixels)\n",
    "        self.dpi = 96\n",
    "        self.cm_to_pixels = self.dpi / 2.54  # 1 inch = 2.54 cm\n",
    "        \n",
    "        # Point visualization settings\n",
    "        self.points_config = {\n",
    "            'color': (0, 0, 255),    # Rouge en BGR\n",
    "            'radius': int(1.2 * self.cm_to_pixels),  # ~1.2cm de rayon (triplé)\n",
    "            'thickness': int(0.1 * self.cm_to_pixels)  # ~0.1cm d'épaisseur (doublée)\n",
    "        }\n",
    "        \n",
    "        # Offset settings (conversion cm -> pixels)\n",
    "        self.offset = {\n",
    "            'vertical': int(1.0 * self.cm_to_pixels),    # 1cm vers le haut\n",
    "            'horizontal': int(1.0 * self.cm_to_pixels)   # 1cm horizontal\n",
    "        }\n",
    "        \n",
    "        # Paramètres de filtrage\n",
    "        self.smoothing_factor = 0.8        # Lissage principal\n",
    "        self.velocity_weight = 0.2         # Poids de la vélocité\n",
    "        self.position_history_size = 3     # Historique court pour plus de réactivité\n",
    "\n",
    "    def _verify_files(self):\n",
    "        if not os.path.exists(self.video_path):\n",
    "            raise FileNotFoundError(f\"Fichier vidéo manquant : {self.video_path}\")\n",
    "        if not os.path.exists(self.data_path):\n",
    "            raise FileNotFoundError(f\"Fichier de données manquant : {self.data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95c781d-fdd8-490d-8e2d-bd6a4d7262e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecisePositionTracker:\n",
    "    \"\"\"Gère le suivi précis de la position avec historique.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.position_history = []\n",
    "        self.velocity = (0, 0)\n",
    "        \n",
    "    def update(self, new_position):\n",
    "        \"\"\"Met à jour la position avec lissage.\"\"\"\n",
    "        if not self.position_history:\n",
    "            self.position_history = [new_position] * self.config.position_history_size\n",
    "            return new_position\n",
    "        \n",
    "        # Calculer la vélocité actuelle\n",
    "        current_velocity = (\n",
    "            new_position[0] - self.position_history[-1][0],\n",
    "            new_position[1] - self.position_history[-1][1]\n",
    "        )\n",
    "        \n",
    "        # Mettre à jour la vélocité lissée\n",
    "        self.velocity = (\n",
    "            self.velocity[0] * (1 - self.config.velocity_weight) + current_velocity[0] * self.config.velocity_weight,\n",
    "            self.velocity[1] * (1 - self.config.velocity_weight) + current_velocity[1] * self.config.velocity_weight\n",
    "        )\n",
    "        \n",
    "        # Appliquer le lissage\n",
    "        smoothed_position = (\n",
    "            int(self.config.smoothing_factor * self.position_history[-1][0] +\n",
    "                (1 - self.config.smoothing_factor) * new_position[0]),\n",
    "            int(self.config.smoothing_factor * self.position_history[-1][1] +\n",
    "                (1 - self.config.smoothing_factor) * new_position[1])\n",
    "        )\n",
    "        \n",
    "        # Mettre à jour l'historique\n",
    "        self.position_history.append(smoothed_position)\n",
    "        self.position_history = self.position_history[-self.config.position_history_size:]\n",
    "        \n",
    "        return smoothed_position\n",
    "        \n",
    "    def get_movement_direction(self):\n",
    "        \"\"\"Détermine la direction du mouvement.\"\"\"\n",
    "        if len(self.position_history) < 2:\n",
    "            return 0\n",
    "        \n",
    "        # Utiliser la vélocité pour déterminer la direction\n",
    "        if abs(self.velocity[0]) < 0.1:  # Seuil minimal de mouvement\n",
    "            return 0\n",
    "        return 1 if self.velocity[0] > 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb0fa87-2b81-4d8d-b09f-886dc386c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeTrackingDataProcessor:\n",
    "    \"\"\"Handles loading and processing of eye tracking data.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data = None\n",
    "        self.frame_count = 0\n",
    "        self.current_row = 0\n",
    "        self.increment = 0\n",
    "        self.position_tracker = PrecisePositionTracker(config)\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(\n",
    "            self.config.data_path,\n",
    "            delimiter='\\t',\n",
    "            encoding='utf-8',\n",
    "            low_memory=False\n",
    "        )\n",
    "        # Utiliser plus de colonnes pour la précision\n",
    "        self.eye_data = self.data.loc[1:, [\n",
    "            \"L POR X [px]\", \"L POR Y [px]\",\n",
    "            \"R POR X [px]\", \"R POR Y [px]\",\n",
    "            \"L EPOS X\", \"L EPOS Y\", \"L EPOS Z\",\n",
    "            \"R EPOS X\", \"R EPOS Y\", \"R EPOS Z\"\n",
    "        ]]\n",
    "        \n",
    "    def initialize_processing(self, frame_count):\n",
    "        self.frame_count = frame_count\n",
    "        self.increment = len(self.eye_data) / frame_count\n",
    "        \n",
    "    def get_coordinates(self, target_resolution):\n",
    "        if int(self.current_row) >= len(self.eye_data) - 1:\n",
    "            return None\n",
    "            \n",
    "        # Obtenir les coordonnées de base\n",
    "        current = self._scale_coordinates(\n",
    "            self.eye_data.iloc[int(self.current_row)],\n",
    "            target_resolution\n",
    "        )\n",
    "        \n",
    "        # Appliquer le tracking précis\n",
    "        tracked_position = self.position_tracker.update(current)\n",
    "        \n",
    "        # Appliquer les offsets\n",
    "        final_position = self._apply_offsets(tracked_position)\n",
    "        \n",
    "        self.current_row += self.increment\n",
    "        return final_position\n",
    "        \n",
    "    def _scale_coordinates(self, point_data, target_resolution):\n",
    "        # Moyenner les coordonnées gauche et droite pour plus de précision\n",
    "        x = (float(point_data[\"L POR X [px]\"]) + float(point_data[\"R POR X [px]\"])) / 2\n",
    "        y = (float(point_data[\"L POR Y [px]\"]) + float(point_data[\"R POR Y [px]\"])) / 2\n",
    "        \n",
    "        # Mise à l'échelle\n",
    "        x = x / self.config.source_resolution[0] * target_resolution[0]\n",
    "        y = y / self.config.source_resolution[1] * target_resolution[1]\n",
    "        \n",
    "        return (int(x), int(y))\n",
    "        \n",
    "    def _apply_offsets(self, position):\n",
    "        \"\"\"Applique les décalages vertical et horizontal.\"\"\"\n",
    "        movement_direction = self.position_tracker.get_movement_direction()\n",
    "        \n",
    "        x = position[0] + (movement_direction * self.config.offset['horizontal'])\n",
    "        y = position[1] - self.config.offset['vertical']  # Toujours décalé vers le haut\n",
    "        \n",
    "        return (int(x), int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df230dc0-b825-4372-a5c6-f52b1c268429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointVisualizer:\n",
    "    \"\"\"Handles the visualization of eye tracking points on video frames.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def process_frame(self, frame, point):\n",
    "        \"\"\"Dessine le point de regard avec des effets pour améliorer la visibilité.\"\"\"\n",
    "        if not self._are_coordinates_valid(point, frame.shape):\n",
    "            return frame\n",
    "            \n",
    "        # Créer un masque pour le point\n",
    "        mask = np.zeros_like(frame)\n",
    "        \n",
    "        # Dessiner d'abord un cercle plus grand et flou pour l'effet de halo\n",
    "        cv2.circle(\n",
    "            mask,\n",
    "            point,\n",
    "            self.config.points_config['radius'] + 10,\n",
    "            self.config.points_config['color'],\n",
    "            -1  # Remplir le cercle\n",
    "        )\n",
    "        \n",
    "        # Ajouter un flou pour créer un effet de halo\n",
    "        mask = cv2.GaussianBlur(mask, (35, 35), 0)\n",
    "        \n",
    "        # Créer un second masque pour le cercle principal\n",
    "        main_circle = np.zeros_like(frame)\n",
    "        cv2.circle(\n",
    "            main_circle,\n",
    "            point,\n",
    "            self.config.points_config['radius'],\n",
    "            self.config.points_config['color'],\n",
    "            self.config.points_config['thickness']\n",
    "        )\n",
    "        \n",
    "        # Combiner les masques avec la frame\n",
    "        result = cv2.addWeighted(frame, 1.0, mask, 0.3, 0)  # Halo subtil\n",
    "        result = cv2.addWeighted(result, 1.0, main_circle, 0.9, 0)  # Cercle principal bien visible\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _are_coordinates_valid(self, point, frame_shape):\n",
    "        \"\"\"Vérifie si les coordonnées sont dans les limites de la frame.\"\"\"\n",
    "        return (point and 0 <= point[0] < frame_shape[1] and \n",
    "                0 <= point[1] < frame_shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83ce4ff-6e22-4fb9-833a-8d7fcb406809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    \"\"\"Handles video input/output operations with audio support.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.cap = None\n",
    "        self.out = None\n",
    "        self.temp_video_path = \"temp_output.mp4\"\n",
    "        self.frame_size = None\n",
    "        self.fps = None\n",
    "        self.frame_count = None\n",
    "        \n",
    "    def open_video(self):\n",
    "        self.cap = cv2.VideoCapture(self.config.video_path)\n",
    "        \n",
    "        # Get video properties\n",
    "        self.frame_size = (\n",
    "            int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        )\n",
    "        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Initialize video writer with H.264 codec\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter(\n",
    "            self.temp_video_path,\n",
    "            fourcc,\n",
    "            self.fps,\n",
    "            self.frame_size,\n",
    "            True  # isColor\n",
    "        )\n",
    "        \n",
    "        return self.frame_count\n",
    "        \n",
    "    def read_frame(self):\n",
    "        return self.cap.read()\n",
    "        \n",
    "    def write_frame(self, frame):\n",
    "        self.out.write(frame)\n",
    "        \n",
    "    def release(self):\n",
    "        \"\"\"Release resources and merge audio with video.\"\"\"\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        if self.out:\n",
    "            self.out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        try:\n",
    "            # Merge audio from original video with processed video using ffmpeg\n",
    "            import subprocess\n",
    "            command = [\n",
    "                'ffmpeg',\n",
    "                '-y',                     # Overwrite output file if exists\n",
    "                '-i', self.temp_video_path,   # Input processed video\n",
    "                '-i', self.config.video_path, # Input original video (for audio)\n",
    "                '-c:v', 'libx264',           # Use H.264 codec\n",
    "                '-preset', 'slower',         # Higher quality preset\n",
    "                '-crf', '17',               # High quality (15-18 is considered visually lossless)\n",
    "                '-c:a', 'copy',             # Copy audio without re-encoding\n",
    "                '-movflags', '+faststart',   # Enable streaming\n",
    "                '-pix_fmt', 'yuv420p',      # Ensure compatibility\n",
    "                self.config.output_path\n",
    "            ]\n",
    "            subprocess.run(command, check=True)\n",
    "            \n",
    "            # Clean up temporary file\n",
    "            if os.path.exists(self.temp_video_path):\n",
    "                os.remove(self.temp_video_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la fusion audio/vidéo : {e}\")\n",
    "            print(\"La vidéo sans audio a été sauvegardée comme solution de repli.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2817d508-d765-4aca-bb9f-43970c2358fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "  configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:11.21, start: 0.000000, bitrate: 1781 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 960x720 [SAR 1:1 DAR 4:3], 1780 kb/s, 24 fps, 24 tbr, 12288 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[avi @ 0x558571843240] non-interleaved AVI\n",
      "Input #1, avi, from 'assets/Test Your Awareness.avi':\n",
      "  Duration: 00:01:08.44, start: 0.000000, bitrate: 2633 kb/s\n",
      "  Stream #1:0: Video: mpeg4 (Simple Profile) (XVID / 0x44495658), yuv420p, 960x720 [SAR 1:1 DAR 4:3], 2224 kb/s, 24.97 fps, 24.97 tbr, 24.97 tbn\n",
      "  Stream #1:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, fltp, 320 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "  Stream #1:1 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x558571947280] using SAR=1/1\n",
      "[libx264 @ 0x558571947280] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x558571947280] profile High, level 4.0, 4:2:0, 8-bit\n",
      "Output #0, avi, to 'assets/EyeTrackingMVP2.avi':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    ISFT            : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: h264 (H264 / 0x34363248), yuv420p(progressive), 960x720 [SAR 1:1 DAR 4:3], q=2-31, 24 fps, 24 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, fltp, 320 kb/s\n",
      "frame= 1547 fps= 94 q=22.0 size=   15616kB time=00:01:07.99 bitrate=1881.5kbits/s speed=4.13x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidéo avec effet eye tracker enregistrée sous : assets/EyeTrackingMVP2.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/avi @ 0x558571856980] video:13371kB audio:2688kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.734587%\n",
      "frame= 1709 fps=102 q=-1.0 Lsize=   16177kB time=00:01:11.08 bitrate=1864.3kbits/s speed=4.25x    \n",
      "[libx264 @ 0x558571947280] frame I:8     Avg QP: 7.35  size: 29179\n",
      "[libx264 @ 0x558571947280] frame P:1002  Avg QP:14.64  size: 11413\n",
      "[libx264 @ 0x558571947280] frame B:699   Avg QP:15.36  size:  2894\n",
      "[libx264 @ 0x558571947280] consecutive B-frames: 41.3%  5.5% 21.4% 31.8%\n",
      "[libx264 @ 0x558571947280] mb I  I16..4: 49.7% 43.0%  7.3%\n",
      "[libx264 @ 0x558571947280] mb P  I16..4:  1.8% 11.1%  0.8%  P16..4: 32.2%  7.1%  4.4%  0.1%  0.0%    skip:42.5%\n",
      "[libx264 @ 0x558571947280] mb B  I16..4:  0.2%  1.2%  0.1%  B16..8: 16.6%  2.6%  0.6%  direct: 0.7%  skip:78.0%  L0:67.5% L1:21.7% BI:10.8%\n",
      "[libx264 @ 0x558571947280] 8x8 transform intra:79.1% inter:76.5%\n",
      "[libx264 @ 0x558571947280] direct mvs  spatial:98.1% temporal:1.9%\n",
      "[libx264 @ 0x558571947280] coded y,uvDC,uvAC intra: 64.9% 56.6% 12.6% inter: 10.7% 9.0% 1.2%\n",
      "[libx264 @ 0x558571947280] i16 v,h,dc,p: 36% 37% 21%  6%\n",
      "[libx264 @ 0x558571947280] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 27% 32%  3%  3%  4%  3%  4%  4%\n",
      "[libx264 @ 0x558571947280] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 30% 27%  9%  4%  6%  9%  6%  5%  4%\n",
      "[libx264 @ 0x558571947280] i8c dc,h,v,p: 33% 36% 25%  7%\n",
      "[libx264 @ 0x558571947280] Weighted P-Frames: Y:0.4% UV:0.1%\n",
      "[libx264 @ 0x558571947280] ref P L0: 77.4%  8.8%  7.5%  2.1%  1.3%  1.0%  0.9%  0.7%  0.4%  0.0%\n",
      "[libx264 @ 0x558571947280] ref B L0: 83.1%  9.4%  3.2%  1.6%  1.2%  1.1%  0.4%\n",
      "[libx264 @ 0x558571947280] ref B L1: 96.8%  3.2%\n",
      "[libx264 @ 0x558571947280] kb/s:1538.24\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "    video_processor = VideoProcessor(config)\n",
    "    data_processor = EyeTrackingDataProcessor(config)\n",
    "    point_visualizer = PointVisualizer(config)\n",
    "    \n",
    "    try:\n",
    "        frame_count = video_processor.open_video()\n",
    "        data_processor.load_data()\n",
    "        data_processor.initialize_processing(frame_count)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = video_processor.read_frame()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            coords = data_processor.get_coordinates(video_processor.frame_size)\n",
    "            if coords is not None:\n",
    "                frame = point_visualizer.process_frame(frame, coords)\n",
    "            \n",
    "            video_processor.write_frame(frame)\n",
    "            \n",
    "    finally:\n",
    "        video_processor.release()\n",
    "        print(f\"Vidéo avec effet eye tracker enregistrée sous : {config.output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f73eb-8da8-4db5-a842-4170534d4597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1872db0b-7077-4657-b275-691d5dad4791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "  configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'temp_output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:11.21, start: 0.000000, bitrate: 1194 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 960x720 [SAR 1:1 DAR 4:3], 1193 kb/s, 24 fps, 24 tbr, 12288 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[avi @ 0x561e01dd16c0] non-interleaved AVI\n",
      "Input #1, avi, from 'assets/Test Your Awareness.avi':\n",
      "  Duration: 00:01:08.44, start: 0.000000, bitrate: 2633 kb/s\n",
      "  Stream #1:0: Video: mpeg4 (Simple Profile) (XVID / 0x44495658), yuv420p, 960x720 [SAR 1:1 DAR 4:3], 2224 kb/s, 24.97 fps, 24.97 tbr, 24.97 tbn\n",
      "  Stream #1:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, fltp, 320 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "  Stream #1:1 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x561e01ed52c0] using SAR=1/1\n",
      "[libx264 @ 0x561e01ed52c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x561e01ed52c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "Output #0, avi, to 'assets/EyeTrackingMVP2.avi':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    ISFT            : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: h264 (H264 / 0x34363248), yuv420p(progressive), 960x720 [SAR 1:1 DAR 4:3], q=2-31, 24 fps, 24 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 48000 Hz, stereo, fltp, 320 kb/s\n",
      "frame= 1242 fps=351 q=28.0 size=    7680kB time=00:00:54.45 bitrate=1155.3kbits/s speed=15.4x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidéo avec effet eye tracker enregistrée sous : assets/EyeTrackingMVP2.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/avi @ 0x561e01de4640] video:5960kB audio:2688kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.363896%\n",
      "frame= 1709 fps=429 q=-1.0 Lsize=    8765kB time=00:01:11.08 bitrate=1010.2kbits/s speed=17.9x    \n",
      "[libx264 @ 0x561e01ed52c0] frame I:16    Avg QP:16.14  size: 11922\n",
      "[libx264 @ 0x561e01ed52c0] frame P:966   Avg QP:20.01  size:  5527\n",
      "[libx264 @ 0x561e01ed52c0] frame B:727   Avg QP:20.53  size:   788\n",
      "[libx264 @ 0x561e01ed52c0] consecutive B-frames: 39.0% 11.8%  3.3% 45.9%\n",
      "[libx264 @ 0x561e01ed52c0] mb I  I16..4: 38.8% 60.1%  1.1%\n",
      "[libx264 @ 0x561e01ed52c0] mb P  I16..4:  3.0% 11.0%  0.1%  P16..4: 33.9%  4.3%  1.5%  0.0%  0.0%    skip:46.1%\n",
      "[libx264 @ 0x561e01ed52c0] mb B  I16..4:  0.2%  0.6%  0.1%  B16..8: 10.1%  0.6%  0.1%  direct: 0.1%  skip:88.4%  L0:61.4% L1:36.0% BI: 2.6%\n",
      "[libx264 @ 0x561e01ed52c0] 8x8 transform intra:75.8% inter:96.9%\n",
      "[libx264 @ 0x561e01ed52c0] coded y,uvDC,uvAC intra: 45.6% 44.1% 1.8% inter: 5.0% 5.0% 0.2%\n",
      "[libx264 @ 0x561e01ed52c0] i16 v,h,dc,p: 36% 38% 15% 10%\n",
      "[libx264 @ 0x561e01ed52c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 29% 28%  2%  3%  4%  3%  3%  3%\n",
      "[libx264 @ 0x561e01ed52c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 22% 21%  5%  7%  6%  5%  4%  3%\n",
      "[libx264 @ 0x561e01ed52c0] i8c dc,h,v,p: 50% 26% 21%  3%\n",
      "[libx264 @ 0x561e01ed52c0] Weighted P-Frames: Y:0.6% UV:0.1%\n",
      "[libx264 @ 0x561e01ed52c0] ref P L0: 78.8%  7.8% 10.3%  3.1%  0.0%\n",
      "[libx264 @ 0x561e01ed52c0] ref B L0: 81.5% 16.6%  1.9%\n",
      "[libx264 @ 0x561e01ed52c0] ref B L1: 96.9%  3.1%\n",
      "[libx264 @ 0x561e01ed52c0] kb/s:685.63\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration for the eye tracking visualization.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Video paths\n",
    "        self.video_path = \"assets/Test Your Awareness.avi\"\n",
    "        self.data_path = \"assets/DataPOR.csv\"\n",
    "        self.output_path = \"assets/EyeTrackingMVP2.avi\"\n",
    "        \n",
    "        self._verify_files()\n",
    "        \n",
    "        # Resolution mapping\n",
    "        self.source_resolution = (1600, 1050)\n",
    "        \n",
    "        # Point visualization settings\n",
    "        self.points_config = {\n",
    "            'color': (0, 0, 255),    # Rouge en BGR\n",
    "            'radius': 25,            # Rayon augmenté\n",
    "            'thickness': 2,          # Épaisseur du cercle\n",
    "        }\n",
    "        \n",
    "        # Offset settings (en pixels)\n",
    "        self.offset = {\n",
    "            'vertical': 10,          # 0.5cm vers le haut\n",
    "            'horizontal': 20,        # 1cm horizontal\n",
    "            'movement_threshold': 60  # Seuil de 3cm pour le déplacement horizontal\n",
    "        }\n",
    "        \n",
    "        # Video effect settings\n",
    "        self.video_blur = (25, 25)   # Flou augmenté\n",
    "        \n",
    "        # Paramètres de filtrage améliorés\n",
    "        self.smoothing_factor = 0.85    # Facteur de lissage principal\n",
    "        self.velocity_weight = 0.15     # Poids réduit pour la vélocité\n",
    "        self.position_history_size = 7   # Historique augmenté\n",
    "        self.filter_window = 5          # Fenêtre pour le filtre médian\n",
    "\n",
    "    def _verify_files(self):\n",
    "        if not os.path.exists(self.video_path):\n",
    "            raise FileNotFoundError(f\"Fichier vidéo manquant : {self.video_path}\")\n",
    "        if not os.path.exists(self.data_path):\n",
    "            raise FileNotFoundError(f\"Fichier de données manquant : {self.data_path}\")\n",
    "\n",
    "\n",
    "class PrecisePositionTracker:\n",
    "    \"\"\"Gère le suivi précis de la position avec historique.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.position_history = []\n",
    "        self.velocity = (0, 0)\n",
    "        \n",
    "    def update(self, new_position):\n",
    "        \"\"\"Met à jour la position avec lissage et correction de vélocité.\"\"\"\n",
    "        if not self.position_history:\n",
    "            self.position_history = [new_position] * self.config.position_history_size\n",
    "            return new_position\n",
    "            \n",
    "        # Calculer la vélocité actuelle\n",
    "        current_velocity = (\n",
    "            new_position[0] - self.position_history[-1][0],\n",
    "            new_position[1] - self.position_history[-1][1]\n",
    "        )\n",
    "        \n",
    "        # Mettre à jour la vélocité lissée\n",
    "        self.velocity = (\n",
    "            self.velocity[0] * (1 - self.config.velocity_weight) + current_velocity[0] * self.config.velocity_weight,\n",
    "            self.velocity[1] * (1 - self.config.velocity_weight) + current_velocity[1] * self.config.velocity_weight\n",
    "        )\n",
    "        \n",
    "        # Appliquer le lissage avec la vélocité\n",
    "        smoothed_position = (\n",
    "            int(self.config.smoothing_factor * self.position_history[-1][0] +\n",
    "                (1 - self.config.smoothing_factor) * new_position[0] +\n",
    "                self.velocity[0] * self.config.velocity_weight),\n",
    "            int(self.config.smoothing_factor * self.position_history[-1][1] +\n",
    "                (1 - self.config.smoothing_factor) * new_position[1] +\n",
    "                self.velocity[1] * self.config.velocity_weight)\n",
    "        )\n",
    "        \n",
    "        # Mettre à jour l'historique\n",
    "        self.position_history.append(smoothed_position)\n",
    "        self.position_history = self.position_history[-self.config.position_history_size:]\n",
    "        \n",
    "        return smoothed_position\n",
    "        \n",
    "    def get_movement_direction(self):\n",
    "        \"\"\"Détermine la direction du mouvement pour ajuster les offsets.\"\"\"\n",
    "        if len(self.position_history) < 2:\n",
    "            return 0\n",
    "            \n",
    "        dx = self.velocity[0]\n",
    "        if abs(dx) < 1:  # Seuil pour éviter les micro-mouvements\n",
    "            return 0\n",
    "        return 1 if dx > 0 else -1\n",
    "\n",
    "\n",
    "class EyeTrackingDataProcessor:\n",
    "    \"\"\"Handles loading and processing of eye tracking data.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data = None\n",
    "        self.frame_count = 0\n",
    "        self.current_row = 0\n",
    "        self.increment = 0\n",
    "        self.position_tracker = PrecisePositionTracker(config)\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(\n",
    "            self.config.data_path,\n",
    "            delimiter='\\t',\n",
    "            encoding='utf-8',\n",
    "            low_memory=False\n",
    "        )\n",
    "        # Utiliser plus de colonnes pour la précision\n",
    "        self.eye_data = self.data.loc[1:, [\n",
    "            \"L POR X [px]\", \"L POR Y [px]\",\n",
    "            \"R POR X [px]\", \"R POR Y [px]\",\n",
    "            \"L EPOS X\", \"L EPOS Y\", \"L EPOS Z\",\n",
    "            \"R EPOS X\", \"R EPOS Y\", \"R EPOS Z\"\n",
    "        ]]\n",
    "        \n",
    "    def initialize_processing(self, frame_count):\n",
    "        self.frame_count = frame_count\n",
    "        self.increment = len(self.eye_data) / frame_count\n",
    "        \n",
    "    def get_coordinates(self, target_resolution):\n",
    "        if int(self.current_row) >= len(self.eye_data) - 1:\n",
    "            return None\n",
    "            \n",
    "        # Obtenir les coordonnées de base\n",
    "        current = self._scale_coordinates(\n",
    "            self.eye_data.iloc[int(self.current_row)],\n",
    "            target_resolution\n",
    "        )\n",
    "        \n",
    "        # Appliquer le tracking précis\n",
    "        tracked_position = self.position_tracker.update(current)\n",
    "        \n",
    "        # Appliquer les offsets\n",
    "        final_position = self._apply_offsets(tracked_position)\n",
    "        \n",
    "        self.current_row += self.increment\n",
    "        return final_position\n",
    "        \n",
    "    def _scale_coordinates(self, point_data, target_resolution):\n",
    "        # Moyenner les coordonnées gauche et droite pour plus de précision\n",
    "        x = (float(point_data[\"L POR X [px]\"]) + float(point_data[\"R POR X [px]\"])) / 2\n",
    "        y = (float(point_data[\"L POR Y [px]\"]) + float(point_data[\"R POR Y [px]\"])) / 2\n",
    "        \n",
    "        # Mise à l'échelle\n",
    "        x = x / self.config.source_resolution[0] * target_resolution[0]\n",
    "        y = y / self.config.source_resolution[1] * target_resolution[1]\n",
    "        \n",
    "        return (int(x), int(y))\n",
    "        \n",
    "    def _apply_offsets(self, position):\n",
    "        \"\"\"Applique les décalages vertical et horizontal.\"\"\"\n",
    "        movement_direction = self.position_tracker.get_movement_direction()\n",
    "        \n",
    "        x = position[0] + (movement_direction * self.config.offset['horizontal'])\n",
    "        y = position[1] - self.config.offset['vertical']  # Toujours décalé vers le haut\n",
    "        \n",
    "        return (int(x), int(y))\n",
    "\n",
    "\n",
    "class PointVisualizer:\n",
    "    \"\"\"Handles the visualization of eye tracking points on video frames.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def process_frame(self, frame, point):\n",
    "        if not self._are_coordinates_valid(point, frame.shape):\n",
    "            return frame\n",
    "            \n",
    "        # Appliquer le flou sur toute la vidéo\n",
    "        blurred_frame = cv2.GaussianBlur(frame, self.config.video_blur, 0)\n",
    "        \n",
    "        # Dessiner le cercle précis sur la frame floutée\n",
    "        cv2.circle(\n",
    "            blurred_frame,\n",
    "            point,\n",
    "            self.config.points_config['radius'],\n",
    "            self.config.points_config['color'],\n",
    "            self.config.points_config['thickness']\n",
    "        )\n",
    "        \n",
    "        return blurred_frame\n",
    "    \n",
    "    def _are_coordinates_valid(self, point, frame_shape):\n",
    "        return (point and 0 <= point[0] < frame_shape[1] and \n",
    "                0 <= point[1] < frame_shape[0])\n",
    "\n",
    "\n",
    "class VideoProcessor:\n",
    "    \"\"\"Handles video input/output operations with audio support.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.cap = None\n",
    "        self.out = None\n",
    "        self.temp_video_path = \"temp_output.mp4\"\n",
    "        self.frame_size = None\n",
    "        self.fps = None\n",
    "        self.frame_count = None\n",
    "        \n",
    "    def open_video(self):\n",
    "        self.cap = cv2.VideoCapture(self.config.video_path)\n",
    "        \n",
    "        # Get video properties\n",
    "        self.frame_size = (\n",
    "            int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        )\n",
    "        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Initialize video writer with H.264 codec\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter(\n",
    "            self.temp_video_path,\n",
    "            fourcc,\n",
    "            self.fps,\n",
    "            self.frame_size,\n",
    "            True  # isColor\n",
    "        )\n",
    "        \n",
    "        return self.frame_count\n",
    "        \n",
    "    def read_frame(self):\n",
    "        return self.cap.read()\n",
    "        \n",
    "    def write_frame(self, frame):\n",
    "        self.out.write(frame)\n",
    "        \n",
    "    def release(self):\n",
    "        \"\"\"Release resources and merge audio with video.\"\"\"\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        if self.out:\n",
    "            self.out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        try:\n",
    "            # Merge audio from original video with processed video using ffmpeg\n",
    "            import subprocess\n",
    "            command = [\n",
    "                'ffmpeg',\n",
    "                '-y',  # Overwrite output file if exists\n",
    "                '-i', self.temp_video_path,  # Input processed video\n",
    "                '-i', self.config.video_path, # Input original video (for audio)\n",
    "                '-c:v', 'libx264',           # Use H.264 codec\n",
    "                '-preset', 'medium',          # Encoding preset\n",
    "                '-crf', '23',                # Quality setting\n",
    "                '-c:a', 'copy',              # Copy audio without re-encoding\n",
    "                self.config.output_path\n",
    "            ]\n",
    "            subprocess.run(command, check=True)\n",
    "            \n",
    "            # Clean up temporary file\n",
    "            if os.path.exists(self.temp_video_path):\n",
    "                os.remove(self.temp_video_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la fusion audio/vidéo : {e}\")\n",
    "            print(\"La vidéo sans audio a été sauvegardée comme solution de repli.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "    video_processor = VideoProcessor(config)\n",
    "    data_processor = EyeTrackingDataProcessor(config)\n",
    "    point_visualizer = PointVisualizer(config)\n",
    "    \n",
    "    try:\n",
    "        frame_count = video_processor.open_video()\n",
    "        data_processor.load_data()\n",
    "        data_processor.initialize_processing(frame_count)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = video_processor.read_frame()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            coords = data_processor.get_coordinates(video_processor.frame_size)\n",
    "            if coords is not None:\n",
    "                frame = point_visualizer.process_frame(frame, coords)\n",
    "            \n",
    "            video_processor.write_frame(frame)\n",
    "            \n",
    "    finally:\n",
    "        video_processor.release()\n",
    "        print(f\"Vidéo avec effet eye tracker enregistrée sous : {config.output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ba9cb-f554-4ce1-857b-6070c843179c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

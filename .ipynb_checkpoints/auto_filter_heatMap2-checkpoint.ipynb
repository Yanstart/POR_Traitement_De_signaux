{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8330290f-fb24-40c3-84b1-397f6c7440ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration manager for eye tracking visualization.\n",
    "    \n",
    "    This class handles all configuration parameters for eye gaze tracking visualization:\n",
    "    - File paths and validation\n",
    "    - Screen resolution and DPI settings\n",
    "    - Point visualization parameters\n",
    "    - Gaze movement smoothing parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Internal cache for computed values\n",
    "        self._cache = {}\n",
    "        \n",
    "        # Input/Output file paths\n",
    "        # Note: These paths are relative to the assets directory\n",
    "        self.video_path = \"assets/Test Your Awareness.avi\"  # Source video\n",
    "        self.data_path = \"assets/DataPOR.csv\"              # Eye tracking data\n",
    "        self.output_path = \"assets/LatestEyeTracking.avi\"    # Output video\n",
    "        \n",
    "        # Validate file existence on initialization\n",
    "        self._verify_files()\n",
    "        \n",
    "        # Source video resolution settings\n",
    "        # Important: Must match the resolution of eye tracking data capture\n",
    "        self._source_resolution = (1600, 1050)\n",
    "        \n",
    "        # DPI and pixel conversion settings\n",
    "        # Used to ensure consistent visualization across different displays\n",
    "        self._dpi = 96  # Standard screen DPI\n",
    "        self._cm_to_pixels = self._dpi / 2.54  # Convert centimeters to pixels (1 inch = 2.54 cm)\n",
    "        \n",
    "        # Gaze point visualization settings\n",
    "        # These determine how the gaze point appears in the video\n",
    "        self._points_config = {\n",
    "            'color': (0, 0, 255),  # BGR format (Red in this case)\n",
    "            'radius': int(1.2 * self._cm_to_pixels),    # ~1.2cm radius in pixels\n",
    "            'thickness': int(0.1 * self._cm_to_pixels)  # ~0.1cm thickness in pixels\n",
    "        }\n",
    "        \n",
    "        # Gaze point offset settings\n",
    "        # Compensates for potential calibration offsets\n",
    "        self._offset = {\n",
    "            'vertical': int(1.0 * self._cm_to_pixels),    # 1cm up\n",
    "            'horizontal': int(1.0 * self._cm_to_pixels)   # 1cm horizontal\n",
    "        }\n",
    "        \n",
    "        # Gaze movement smoothing parameters\n",
    "        # These help reduce jitter and create more natural eye movement visualization\n",
    "        self._smoothing_config = {\n",
    "            'smoothing_factor': 0.8,        # Main smoothing weight (higher = smoother)\n",
    "            'velocity_weight': 0.2,         # Velocity influence on movement\n",
    "            'position_history_size': 3      # Number of positions to consider for smoothing\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def source_resolution(self):\n",
    "        \"\"\"Get the source video resolution.\"\"\"\n",
    "        return self._source_resolution\n",
    "\n",
    "    @property\n",
    "    def points_config(self):\n",
    "        \"\"\"Get point visualization settings.\"\"\"\n",
    "        return self._points_config\n",
    "\n",
    "    @property\n",
    "    def offset(self):\n",
    "        \"\"\"Get calibration offset values.\"\"\"\n",
    "        return self._offset\n",
    "\n",
    "    @property\n",
    "    def smoothing_factor(self):\n",
    "        \"\"\"Get the main smoothing factor for gaze movement.\"\"\"\n",
    "        return self._smoothing_config['smoothing_factor']\n",
    "\n",
    "    @property\n",
    "    def velocity_weight(self):\n",
    "        \"\"\"Get the velocity influence weight for movement calculation.\"\"\"\n",
    "        return self._smoothing_config['velocity_weight']\n",
    "\n",
    "    @property\n",
    "    def position_history_size(self):\n",
    "        \"\"\"Get the number of historical positions to use for smoothing.\"\"\"\n",
    "        return self._smoothing_config['position_history_size']\n",
    "\n",
    "    def _verify_files(self):\n",
    "        \"\"\"Verify that all required input files exist.\n",
    "        \n",
    "        Raises:\n",
    "            FileNotFoundError: If any required file is missing\n",
    "        \"\"\"\n",
    "        missing_files = []\n",
    "        \n",
    "        for path, desc in [\n",
    "            (self.video_path, \"Source video file\"),\n",
    "            (self.data_path, \"Eye tracking data file\")\n",
    "        ]:\n",
    "            if not os.path.exists(path):\n",
    "                missing_files.append(f\"{desc}: {path}\")\n",
    "        \n",
    "        if missing_files:\n",
    "            raise FileNotFoundError(\n",
    "                \"Required files not found:\\n\" + \"\\n\".join(missing_files)\n",
    "            )\n",
    "\n",
    "    def get_output_paths(self, base_name=None):\n",
    "        \"\"\"Generate paths for all output files.\n",
    "        \n",
    "        Args:\n",
    "            base_name (str, optional): Base name for output files.\n",
    "                                     Default derives from output_path.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Paths for video, heatmap, and statistics files.\n",
    "        \"\"\"\n",
    "        if base_name is None:\n",
    "            base_name = os.path.splitext(self.output_path)[0]\n",
    "            \n",
    "        return {\n",
    "            'video': f\"{base_name}.avi\",           # Main output video\n",
    "            'heatmap': f\"{base_name}_heatmap.png\", # Final heatmap image\n",
    "            'stats': f\"{base_name}_stats.json\"     # Analysis statistics\n",
    "        }\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Export configuration as a dictionary for logging or saving.\n",
    "        \n",
    "        Returns:\n",
    "            dict: All configuration parameters in a serializable format.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'video_path': self.video_path,\n",
    "            'data_path': self.data_path,\n",
    "            'output_path': self.output_path,\n",
    "            'source_resolution': self._source_resolution,\n",
    "            'dpi': self._dpi,\n",
    "            'points_config': self._points_config,\n",
    "            'offset': self._offset,\n",
    "            'smoothing_config': self._smoothing_config\n",
    "        }\n",
    "\n",
    "    def validate_paths(self):\n",
    "        \"\"\"Validate and prepare output directory structure.\n",
    "        \n",
    "        Creates output directory if needed and verifies write permissions.\n",
    "        \n",
    "        Raises:\n",
    "            PermissionError: If the output directory is not writable.\n",
    "        \"\"\"\n",
    "        output_dir = os.path.dirname(self.output_path)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Verify write permissions with a test file\n",
    "        test_file = os.path.join(output_dir, '.test_write')\n",
    "        try:\n",
    "            with open(test_file, 'w') as f:\n",
    "                f.write('')\n",
    "            os.remove(test_file)\n",
    "        except (IOError, OSError) as e:\n",
    "            raise PermissionError(f\"Cannot write to output directory: {output_dir}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95c781d-fdd8-490d-8e2d-bd6a4d7262e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecisePositionTracker:\n",
    "    \"\"\"Manages precise gaze position tracking with motion smoothing.\n",
    "    \n",
    "    This class implements an advanced position tracking system that:\n",
    "    - Maintains a history of recent gaze positions\n",
    "    - Applies velocity-based smoothing\n",
    "    - Reduces jitter in eye tracking data\n",
    "    - Provides movement direction analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"Initialize the position tracker with configuration parameters.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration object containing smoothing parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize tracking arrays with numpy for better performance\n",
    "        self.position_history = np.zeros((config.position_history_size, 2), dtype=np.float32)\n",
    "        self.current_index = 0\n",
    "        self.is_history_filled = False\n",
    "        \n",
    "        # Velocity tracking for smooth movement\n",
    "        self.velocity = np.zeros(2, dtype=np.float32)\n",
    "        \n",
    "        # Constants for movement detection\n",
    "        self._MOVEMENT_THRESHOLD = 0.1  # Minimal movement detection threshold\n",
    "        self._MIN_VELOCITY_NORM = 1e-5  # Minimum velocity magnitude\n",
    "        \n",
    "        # Initialize smoothing parameters from config\n",
    "        self._smoothing_factor = config.smoothing_factor\n",
    "        self._velocity_weight = config.velocity_weight\n",
    "        self._history_size = config.position_history_size\n",
    "\n",
    "    def update(self, new_position):\n",
    "        \"\"\"Update position tracking with new gaze coordinates.\n",
    "        \n",
    "        Implements a sophisticated position update algorithm that:\n",
    "        1. Calculates instantaneous velocity\n",
    "        2. Updates smoothed velocity\n",
    "        3. Applies position smoothing\n",
    "        4. Updates position history\n",
    "        \n",
    "        Args:\n",
    "            new_position (tuple): New (x, y) gaze position coordinates\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Smoothed (x, y) position coordinates\n",
    "        \"\"\"\n",
    "        new_position = np.array(new_position, dtype=np.float32)\n",
    "        \n",
    "        # First position initialization\n",
    "        if not self.is_history_filled and self.current_index == 0:\n",
    "            self.position_history.fill(0)\n",
    "            self.position_history[0] = new_position\n",
    "            self.current_index = 1\n",
    "            return tuple(map(int, new_position))\n",
    "            \n",
    "        # Calculate instantaneous velocity\n",
    "        last_position = self.position_history[self.current_index - 1]\n",
    "        current_velocity = new_position - last_position\n",
    "        \n",
    "        # Update smoothed velocity using exponential moving average\n",
    "        self.velocity = (\n",
    "            self.velocity * (1 - self._velocity_weight) +\n",
    "            current_velocity * self._velocity_weight\n",
    "        )\n",
    "        \n",
    "        # Apply position smoothing with velocity consideration\n",
    "        smoothed_position = (\n",
    "            last_position * self._smoothing_factor +\n",
    "            new_position * (1 - self._smoothing_factor) +\n",
    "            self.velocity * self._velocity_weight\n",
    "        )\n",
    "        \n",
    "        # Update position history\n",
    "        self.position_history[self.current_index] = smoothed_position\n",
    "        self.current_index = (self.current_index + 1) % self._history_size\n",
    "        \n",
    "        # Mark history as filled if we've completed one cycle\n",
    "        if self.current_index == 0:\n",
    "            self.is_history_filled = True\n",
    "        \n",
    "        # Return integer coordinates for pixel-perfect rendering\n",
    "        return tuple(map(int, smoothed_position))\n",
    "\n",
    "    def get_movement_direction(self):\n",
    "        \"\"\"Analyze movement direction based on current velocity.\n",
    "        \n",
    "        Returns:\n",
    "            int: Movement direction indicator\n",
    "                 1 = moving right\n",
    "                 -1 = moving left\n",
    "                 0 = stationary or minimal movement\n",
    "        \"\"\"\n",
    "        # Calculate velocity magnitude\n",
    "        velocity_x = self.velocity[0]\n",
    "        \n",
    "        # Check if movement is significant\n",
    "        if abs(velocity_x) < self._MOVEMENT_THRESHOLD:\n",
    "            return 0\n",
    "            \n",
    "        # Determine direction based on x velocity\n",
    "        return 1 if velocity_x > 0 else -1\n",
    "\n",
    "    def get_average_velocity(self):\n",
    "        \"\"\"Calculate average velocity over recent history.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Average (dx, dy) velocity components\n",
    "        \"\"\"\n",
    "        if not self.is_history_filled:\n",
    "            return (0.0, 0.0)\n",
    "            \n",
    "        # Calculate velocities between consecutive positions\n",
    "        velocities = np.diff(self.position_history, axis=0)\n",
    "        \n",
    "        # Return average velocity components\n",
    "        return tuple(np.mean(velocities, axis=0))\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset tracker to initial state.\n",
    "        \n",
    "        Useful when starting a new tracking session or after significant gaps in data.\n",
    "        \"\"\"\n",
    "        self.position_history.fill(0)\n",
    "        self.velocity.fill(0)\n",
    "        self.current_index = 0\n",
    "        self.is_history_filled = False\n",
    "\n",
    "    def get_smoothing_info(self):\n",
    "        \"\"\"Get current smoothing parameters for debugging or analysis.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Current smoothing parameters and state\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'smoothing_factor': self._smoothing_factor,\n",
    "            'velocity_weight': self._velocity_weight,\n",
    "            'history_size': self._history_size,\n",
    "            'current_velocity': tuple(self.velocity),\n",
    "            'is_history_filled': self.is_history_filled\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb0fa87-2b81-4d8d-b09f-886dc386c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeTrackingDataProcessor:\n",
    "    \"\"\"Processes and manages eye tracking data from raw input.\n",
    "    \n",
    "    This class handles:\n",
    "    - Loading and preprocessing of eye tracking data\n",
    "    - Coordinate scaling and transformation\n",
    "    - Real-time data processing for video synchronization\n",
    "    - Position tracking with precision enhancement\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define column names as class constants\n",
    "    REQUIRED_COLUMNS = {\n",
    "        'left_x': \"L POR X [px]\",\n",
    "        'left_y': \"L POR Y [px]\",\n",
    "        'right_x': \"R POR X [px]\",\n",
    "        'right_y': \"R POR Y [px]\",\n",
    "        'left_pos_x': \"L EPOS X\",\n",
    "        'left_pos_y': \"L EPOS Y\",\n",
    "        'left_pos_z': \"L EPOS Z\",\n",
    "        'right_pos_x': \"R EPOS X\",\n",
    "        'right_pos_y': \"R EPOS Y\",\n",
    "        'right_pos_z': \"R EPOS Z\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"Initialize the data processor with configuration.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration object containing path and processing parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize data structures\n",
    "        self.data = None\n",
    "        self.eye_data = None\n",
    "        self.frame_count = 0\n",
    "        self.current_row = 0\n",
    "        self.increment = 0\n",
    "        \n",
    "        # Create position tracker instance\n",
    "        self.position_tracker = PrecisePositionTracker(config)\n",
    "        \n",
    "        # Data validation flags\n",
    "        self._data_loaded = False\n",
    "        self._processing_initialized = False\n",
    "        \n",
    "        # Performance optimization: pre-allocate buffers\n",
    "        self._coord_buffer = np.zeros(2, dtype=np.float32)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess eye tracking data from file.\n",
    "        \n",
    "        Raises:\n",
    "            FileNotFoundError: If data file is not found\n",
    "            ValueError: If required columns are missing\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load data with optimized parameters\n",
    "            self.data = pd.read_csv(\n",
    "                self.config.data_path,\n",
    "                delimiter='\\t',\n",
    "                encoding='utf-8',\n",
    "                usecols=list(self.REQUIRED_COLUMNS.values()),\n",
    "                dtype={col: np.float32 for col in self.REQUIRED_COLUMNS.values()},\n",
    "                low_memory=False\n",
    "            )\n",
    "            \n",
    "            # Validate required columns\n",
    "            missing_cols = set(self.REQUIRED_COLUMNS.values()) - set(self.data.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "            \n",
    "            # Extract eye tracking data, skipping header row\n",
    "            self.eye_data = self.data.iloc[1:].copy()\n",
    "            \n",
    "            # Optimize memory usage\n",
    "            self.eye_data = self.eye_data.astype(np.float32)\n",
    "            \n",
    "            self._data_loaded = True\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Eye tracking data file not found: {self.config.data_path}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading eye tracking data: {str(e)}\")\n",
    "\n",
    "    def initialize_processing(self, frame_count):\n",
    "        \"\"\"Initialize data processing for video synchronization.\n",
    "        \n",
    "        Args:\n",
    "            frame_count (int): Total number of video frames to process\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If data hasn't been loaded\n",
    "        \"\"\"\n",
    "        if not self._data_loaded:\n",
    "            raise RuntimeError(\"Data must be loaded before initializing processing\")\n",
    "            \n",
    "        self.frame_count = frame_count\n",
    "        self.increment = len(self.eye_data) / frame_count\n",
    "        self._processing_initialized = True\n",
    "\n",
    "    def get_coordinates(self, target_resolution):\n",
    "        \"\"\"Get processed coordinates for current frame.\n",
    "        \n",
    "        Args:\n",
    "            target_resolution (tuple): Target video resolution (width, height)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Processed (x, y) coordinates or None if end of data\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If processing hasn't been initialized\n",
    "        \"\"\"\n",
    "        if not self._processing_initialized:\n",
    "            raise RuntimeError(\"Processing must be initialized before getting coordinates\")\n",
    "            \n",
    "        if int(self.current_row) >= len(self.eye_data) - 1:\n",
    "            return None\n",
    "            \n",
    "        # Get current data point\n",
    "        current_data = self.eye_data.iloc[int(self.current_row)]\n",
    "        \n",
    "        # Process coordinates\n",
    "        coords = self._process_coordinates(current_data, target_resolution)\n",
    "        \n",
    "        # Update row counter\n",
    "        self.current_row += self.increment\n",
    "        \n",
    "        return coords\n",
    "\n",
    "    def _process_coordinates(self, point_data, target_resolution):\n",
    "        \"\"\"Process raw coordinates with precision enhancement.\n",
    "        \n",
    "        Args:\n",
    "            point_data (pd.Series): Raw eye tracking data point\n",
    "            target_resolution (tuple): Target video resolution\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Processed (x, y) coordinates\n",
    "        \"\"\"\n",
    "        # Average left and right eye coordinates\n",
    "        x = (float(point_data[self.REQUIRED_COLUMNS['left_x']]) + \n",
    "             float(point_data[self.REQUIRED_COLUMNS['right_x']])) / 2\n",
    "        y = (float(point_data[self.REQUIRED_COLUMNS['left_y']]) + \n",
    "             float(point_data[self.REQUIRED_COLUMNS['right_y']])) / 2\n",
    "        \n",
    "        # Scale coordinates to target resolution\n",
    "        x = x / self.config.source_resolution[0] * target_resolution[0]\n",
    "        y = y / self.config.source_resolution[1] * target_resolution[1]\n",
    "        \n",
    "        # Track position with smoothing\n",
    "        return self.position_tracker.update((int(x), int(y)))\n",
    "\n",
    "    def get_processing_stats(self):\n",
    "        \"\"\"Get current processing statistics.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Processing statistics and state information\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'total_rows': len(self.eye_data) if self._data_loaded else 0,\n",
    "            'current_row': self.current_row,\n",
    "            'frame_count': self.frame_count,\n",
    "            'increment': self.increment,\n",
    "            'is_initialized': self._processing_initialized,\n",
    "            'tracker_info': self.position_tracker.get_smoothing_info()\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset processor to initial state.\"\"\"\n",
    "        self.current_row = 0\n",
    "        self.position_tracker.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df230dc0-b825-4372-a5c6-f52b1c268429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointVisualizer:\n",
    "    \"\"\"Manages the visualization of eye tracking points on video frames.\n",
    "    \n",
    "    This class handles:\n",
    "    - Drawing gaze points with enhanced visibility\n",
    "    - Creating visual effects (halos, shadows)\n",
    "    - Optimized frame processing\n",
    "    - Coordinate validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"Initialize the point visualizer with configuration.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration object containing visualization parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        \n",
    "        # Pre-calculate visualization parameters\n",
    "        self._setup_visualization_params()\n",
    "        \n",
    "        # Pre-allocate masks for better performance\n",
    "        self._initialize_masks()\n",
    "\n",
    "    def _setup_visualization_params(self):\n",
    "        \"\"\"Pre-calculate visualization parameters for performance.\"\"\"\n",
    "        self._vis_params = {\n",
    "            'color': self.config.points_config['color'],\n",
    "            'radius': self.config.points_config['radius'],\n",
    "            'thickness': self.config.points_config['thickness'],\n",
    "            'halo_radius': self.config.points_config['radius'] + 10,\n",
    "            'blur_size': (35, 35),\n",
    "            'halo_alpha': 0.3,\n",
    "            'point_alpha': 0.9\n",
    "        }\n",
    "        \n",
    "        # Pre-calculate blur kernel for halo effect\n",
    "        self._blur_kernel = cv2.getGaussianKernel(35, 0)\n",
    "        self._blur_kernel = self._blur_kernel * self._blur_kernel.T\n",
    "\n",
    "    def _initialize_masks(self):\n",
    "        \"\"\"Pre-allocate masks used in visualization.\"\"\"\n",
    "        self._masks = {\n",
    "            'temp': None,  # Will be initialized with first frame\n",
    "            'halo': None,\n",
    "            'main': None\n",
    "        }\n",
    "\n",
    "    def process_frame(self, frame, point):\n",
    "        \"\"\"Process a video frame by adding gaze point visualization.\n",
    "        \n",
    "        Args:\n",
    "            frame (np.ndarray): Input video frame\n",
    "            point (tuple): (x, y) coordinates of gaze point\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Frame with visualized gaze point\n",
    "            \n",
    "        Note:\n",
    "            - Creates a halo effect for better visibility\n",
    "            - Applies smooth blending of effects\n",
    "            - Handles edge cases for point coordinates\n",
    "        \"\"\"\n",
    "        # Validate coordinates\n",
    "        if not self._are_coordinates_valid(point, frame.shape):\n",
    "            return frame\n",
    "            \n",
    "        # Initialize masks if needed\n",
    "        if self._masks['temp'] is None:\n",
    "            shape = frame.shape\n",
    "            for key in self._masks:\n",
    "                self._masks[key] = np.zeros(shape, dtype=frame.dtype)\n",
    "        \n",
    "        # Clear previous masks\n",
    "        for mask in self._masks.values():\n",
    "            mask.fill(0)\n",
    "            \n",
    "        # Draw halo effect\n",
    "        cv2.circle(\n",
    "            self._masks['halo'],\n",
    "            point,\n",
    "            self._vis_params['halo_radius'],\n",
    "            self._vis_params['color'],\n",
    "            -1  # Filled circle\n",
    "        )\n",
    "        \n",
    "        # Apply optimized gaussian blur for halo\n",
    "        self._apply_blur(self._masks['halo'])\n",
    "        \n",
    "        # Draw main point\n",
    "        cv2.circle(\n",
    "            self._masks['main'],\n",
    "            point,\n",
    "            self._vis_params['radius'],\n",
    "            self._vis_params['color'],\n",
    "            self._vis_params['thickness']\n",
    "        )\n",
    "        \n",
    "        # Combine layers efficiently\n",
    "        return self._combine_layers(frame)\n",
    "\n",
    "    def _apply_blur(self, mask):\n",
    "        \"\"\"Apply pre-calculated gaussian blur to mask.\n",
    "        \n",
    "        Args:\n",
    "            mask (np.ndarray): Mask to blur\n",
    "        \"\"\"\n",
    "        cv2.filter2D(mask, -1, self._blur_kernel, mask)\n",
    "\n",
    "    def _combine_layers(self, frame):\n",
    "        \"\"\"Combine all visual layers efficiently.\n",
    "        \n",
    "        Args:\n",
    "            frame (np.ndarray): Original frame\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Combined frame with all effects\n",
    "        \"\"\"\n",
    "        # Create working copy\n",
    "        result = frame.copy()\n",
    "        \n",
    "        # Add halo effect\n",
    "        cv2.addWeighted(\n",
    "            result, 1.0,\n",
    "            self._masks['halo'], self._vis_params['halo_alpha'],\n",
    "            0, result\n",
    "        )\n",
    "        \n",
    "        # Add main point\n",
    "        cv2.addWeighted(\n",
    "            result, 1.0,\n",
    "            self._masks['main'], self._vis_params['point_alpha'],\n",
    "            0, result\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def _are_coordinates_valid(point, frame_shape):\n",
    "        \"\"\"Validate point coordinates against frame dimensions.\n",
    "        \n",
    "        Args:\n",
    "            point (tuple): (x, y) coordinates to validate\n",
    "            frame_shape (tuple): Shape of the frame\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if coordinates are valid\n",
    "        \"\"\"\n",
    "        if point is None:\n",
    "            return False\n",
    "            \n",
    "        x, y = point\n",
    "        height, width = frame_shape[:2]\n",
    "        \n",
    "        return (0 <= x < width) and (0 <= y < height)\n",
    "\n",
    "    def get_visualization_params(self):\n",
    "        \"\"\"Get current visualization parameters.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Current visualization parameters and effects settings\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'visualization_params': self._vis_params.copy(),\n",
    "            'frame_info': {\n",
    "                'mask_shape': self._masks['temp'].shape if self._masks['temp'] is not None else None,\n",
    "                'blur_kernel_size': self._blur_kernel.shape\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83ce4ff-6e22-4fb9-833a-8d7fcb406809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    \"\"\"Handles video processing with audio preservation and optimized I/O operations.\n",
    "    \n",
    "    This class manages:\n",
    "    - Video capture and writing with proper codec handling\n",
    "    - Audio extraction and reintegration\n",
    "    - Memory-efficient frame processing\n",
    "    - Progress tracking and error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class constants for video processing\n",
    "    VIDEO_CODEC = 'mp4v'  # Default codec for temporary video\n",
    "    FINAL_CODEC = 'libx264'  # H.264 codec for final output\n",
    "    QUALITY_CRF = '17'  # High quality (15-18 is visually lossless)\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"Initialize video processor with configuration.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration object containing video parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        \n",
    "        # Video handling objects\n",
    "        self.cap = None  # Video capture\n",
    "        self.out = None  # Video writer\n",
    "        \n",
    "        # Video properties\n",
    "        self.frame_size = None\n",
    "        self.fps = None\n",
    "        self.frame_count = None\n",
    "        self.current_frame = 0\n",
    "        \n",
    "        # Temporary file handling\n",
    "        self.temp_video_path = \"temp_output.mp4\"\n",
    "        \n",
    "        # Performance optimization\n",
    "        self._buffer = None  # Pre-allocated frame buffer\n",
    "        self._processing_stats = {\n",
    "            'frames_processed': 0,\n",
    "            'start_time': None,\n",
    "            'dropped_frames': 0\n",
    "        }\n",
    "\n",
    "    def open_video(self):\n",
    "        \"\"\"Open and initialize video capture and writer.\n",
    "        \n",
    "        Returns:\n",
    "            int: Total number of frames in video\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If video file cannot be opened\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(self.config.video_path)\n",
    "            if not self.cap.isOpened():\n",
    "                raise RuntimeError(f\"Cannot open video file: {self.config.video_path}\")\n",
    "            \n",
    "            # Get video properties\n",
    "            self.frame_size = (\n",
    "                int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            )\n",
    "            self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "            self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            \n",
    "            # Initialize video writer with optimized settings\n",
    "            self._initialize_writer()\n",
    "            \n",
    "            # Initialize performance tracking\n",
    "            self._processing_stats['start_time'] = time.time()\n",
    "            \n",
    "            return self.frame_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.release()  # Clean up on error\n",
    "            raise RuntimeError(f\"Error initializing video processing: {str(e)}\")\n",
    "\n",
    "    def _initialize_writer(self):\n",
    "        \"\"\"Initialize video writer with optimized codec settings.\"\"\"\n",
    "        try:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*self.VIDEO_CODEC)\n",
    "            self.out = cv2.VideoWriter(\n",
    "                self.temp_video_path,\n",
    "                fourcc,\n",
    "                self.fps,\n",
    "                self.frame_size,\n",
    "                True  # isColor\n",
    "            )\n",
    "            \n",
    "            if not self.out.isOpened():\n",
    "                raise RuntimeError(\"Failed to initialize video writer\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error creating video writer: {str(e)}\")\n",
    "\n",
    "    def read_frame(self):\n",
    "        \"\"\"Read next frame from video efficiently.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (success, frame) where success is bool and frame is np.ndarray\n",
    "        \"\"\"\n",
    "        # Pre-allocate buffer for first frame\n",
    "        if self._buffer is None and self.frame_size:\n",
    "            self._buffer = np.empty((self.frame_size[1], self.frame_size[0], 3), \n",
    "                                  dtype=np.uint8)\n",
    "        \n",
    "        success = self.cap.grab()  # Faster than retrieve for sequential access\n",
    "        if not success:\n",
    "            return False, None\n",
    "            \n",
    "        success, frame = self.cap.retrieve()\n",
    "        if success:\n",
    "            self.current_frame += 1\n",
    "            self._processing_stats['frames_processed'] += 1\n",
    "            return True, frame\n",
    "        else:\n",
    "            self._processing_stats['dropped_frames'] += 1\n",
    "            return False, None\n",
    "\n",
    "    def write_frame(self, frame):\n",
    "        \"\"\"Write frame to output video.\n",
    "        \n",
    "        Args:\n",
    "            frame (np.ndarray): Processed frame to write\n",
    "        \"\"\"\n",
    "        if self.out is not None:\n",
    "            self.out.write(frame)\n",
    "\n",
    "    def release(self):\n",
    "        \"\"\"Release resources and finalize video with audio.\n",
    "        \n",
    "        This method:\n",
    "        1. Releases video capture and writer\n",
    "        2. Merges audio from original video\n",
    "        3. Applies final compression settings\n",
    "        4. Cleans up temporary files\n",
    "        \"\"\"\n",
    "        # Release video objects\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        if self.out:\n",
    "            self.out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        try:\n",
    "            self._merge_audio_and_finalize()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error during audio merging: {e}\")\n",
    "            print(\"Falling back to video without audio\")\n",
    "            self._fallback_to_video_only()\n",
    "\n",
    "    def _merge_audio_and_finalize(self):\n",
    "        \"\"\"Merge audio and apply final video compression.\"\"\"\n",
    "        try:\n",
    "            # FFmpeg command for high-quality output\n",
    "            command = [\n",
    "                'ffmpeg',\n",
    "                '-y',  # Overwrite output\n",
    "                '-i', self.temp_video_path,  # Processed video\n",
    "                '-i', self.config.video_path,  # Original video (audio source)\n",
    "                '-c:v', self.FINAL_CODEC,\n",
    "                '-preset', 'slower',  # Higher quality encoding\n",
    "                '-crf', self.QUALITY_CRF,\n",
    "                '-c:a', 'copy',  # Copy audio without re-encoding\n",
    "                '-movflags', '+faststart',  # Enable streaming\n",
    "                '-pix_fmt', 'yuv420p',  # Ensure compatibility\n",
    "                self.config.output_path\n",
    "            ]\n",
    "            \n",
    "            # Execute FFmpeg command\n",
    "            subprocess.run(command, check=True, capture_output=True)\n",
    "            \n",
    "            # Clean up temporary file\n",
    "            if os.path.exists(self.temp_video_path):\n",
    "                os.remove(self.temp_video_path)\n",
    "                \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            raise RuntimeError(f\"FFmpeg error: {e.stderr.decode()}\")\n",
    "\n",
    "    def _fallback_to_video_only(self):\n",
    "        \"\"\"Fall back to processed video without audio if merging fails.\"\"\"\n",
    "        if os.path.exists(self.temp_video_path):\n",
    "            shutil.move(self.temp_video_path, self.config.output_path)\n",
    "\n",
    "    def get_processing_stats(self):\n",
    "        \"\"\"Get current processing statistics.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Processing statistics and performance metrics\n",
    "        \"\"\"\n",
    "        stats = self._processing_stats.copy()\n",
    "        if stats['start_time']:\n",
    "            elapsed_time = time.time() - stats['start_time']\n",
    "            stats.update({\n",
    "                'elapsed_time': elapsed_time,\n",
    "                'fps_average': (stats['frames_processed'] / elapsed_time\n",
    "                              if elapsed_time > 0 else 0),\n",
    "                'progress_percent': (self.current_frame / self.frame_count * 100\n",
    "                                   if self.frame_count else 0)\n",
    "            })\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a750e1f2-421d-4b39-bc1a-02d64fd143c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from threading import Lock\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def calculate_grid_position(x, y, cell_width, cell_height, grid_rows, grid_cols):\n",
    "    \"\"\"Calcule la position dans la grille de manière optimisée.\"\"\"\n",
    "    col = min(max(int(x / cell_width), 0), grid_cols - 1)\n",
    "    row = min(max(int(y / cell_height), 0), grid_rows - 1)\n",
    "    return row, col\n",
    "\n",
    "class HeatmapVisualizer:\n",
    "    \"\"\"Visualiseur de heatmap pour le suivi oculaire.\"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, grid_size=(12, 8)):\n",
    "        self.frame_width, self.frame_height = frame_size\n",
    "        self.grid_cols, self.grid_rows = grid_size\n",
    "        \n",
    "        # Protection pour le multithreading\n",
    "        self.lock = Lock()\n",
    "        \n",
    "        # Configuration de la grille\n",
    "        self.cell_width = self.frame_width // self.grid_cols\n",
    "        self.cell_height = self.frame_height // self.grid_rows\n",
    "        \n",
    "        # Compteurs temporels\n",
    "        self._init_counters()\n",
    "        \n",
    "        # Configuration des couleurs et du kernel\n",
    "        self._setup_colors()\n",
    "        self._setup_kernel()\n",
    "\n",
    "    def _init_counters(self):\n",
    "        \"\"\"Initialise les compteurs de temps.\"\"\"\n",
    "        self.grid_times = np.zeros((self.grid_rows, self.grid_cols), dtype=np.float32)\n",
    "        self.frame_time = 1.0 / 30.0  # Temps estimé par frame (30 FPS)\n",
    "        self.total_time = 0.0\n",
    "        self.last_cell = None\n",
    "\n",
    "    def _setup_colors(self):\n",
    "        \"\"\"Configure le schéma de couleurs vives mais adoucies.\"\"\"\n",
    "        # Couleurs vives mais adoucies (en BGR)\n",
    "        self.colors = np.array([\n",
    "            [180, 180, 120],  # Bleu-vert doux\n",
    "            [140, 200, 100],  # Vert vif adouci\n",
    "            [100, 140, 200],  # Orange doux\n",
    "            [100, 120, 220]   # Rouge vif adouci\n",
    "        ], dtype=np.uint8)\n",
    "        \n",
    "        # Génération du gradient de couleurs\n",
    "        steps = 256\n",
    "        self.color_gradient = np.zeros((steps, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Transition douce entre les couleurs\n",
    "        for i in range(steps):\n",
    "            t = i / (steps - 1)\n",
    "            if t < 0.33:\n",
    "                color1, color2 = self.colors[0], self.colors[1]\n",
    "                factor = t / 0.33\n",
    "            elif t < 0.66:\n",
    "                color1, color2 = self.colors[1], self.colors[2]\n",
    "                factor = (t - 0.33) / 0.33\n",
    "            else:\n",
    "                color1, color2 = self.colors[2], self.colors[3]\n",
    "                factor = (t - 0.66) / 0.34\n",
    "                \n",
    "            self.color_gradient[i] = np.round(\n",
    "                color1 * (1 - factor) + color2 * factor\n",
    "            ).astype(np.uint8)\n",
    "\n",
    "    def _setup_kernel(self):\n",
    "        \"\"\"Configure le kernel gaussien pour l'effet de flou.\"\"\"\n",
    "        kernel_size = min(35, self.cell_width - 1)\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size -= 1\n",
    "        sigma = kernel_size / 6.0\n",
    "        \n",
    "        self.gaussian_kernel = cv2.getGaussianKernel(kernel_size, sigma)\n",
    "        self.gaussian_kernel = (self.gaussian_kernel * self.gaussian_kernel.T).astype(np.float32)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def update_heatmap(self, coords):\n",
    "        \"\"\"Met à jour la heatmap avec de nouvelles coordonnées.\"\"\"\n",
    "        if coords is None or not isinstance(coords, (tuple, list)) or len(coords) != 2:\n",
    "            return\n",
    "            \n",
    "        x, y = coords\n",
    "        if not (0 <= x < self.frame_width and 0 <= y < self.frame_height):\n",
    "            return\n",
    "\n",
    "        with self.lock:\n",
    "            # Calcul de la cellule courante\n",
    "            row, col = calculate_grid_position(\n",
    "                float(x), float(y),\n",
    "                self.cell_width, self.cell_height,\n",
    "                self.grid_rows, self.grid_cols\n",
    "            )\n",
    "            \n",
    "            # Mise à jour des temps\n",
    "            self.grid_times[row, col] += self.frame_time\n",
    "            self.total_time += self.frame_time\n",
    "            \n",
    "            # Application du kernel gaussien pour l'effet de chaleur\n",
    "            half_size = self.kernel_size // 2\n",
    "            y1 = max(0, int(y - half_size))\n",
    "            y2 = min(self.frame_height, int(y + half_size + 1))\n",
    "            x1 = max(0, int(x - half_size))\n",
    "            x2 = min(self.frame_width, int(x + half_size + 1))\n",
    "            \n",
    "            if x2 > x1 and y2 > y1:\n",
    "                kernel_y1 = max(0, half_size - (y - y1))\n",
    "                kernel_y2 = min(self.kernel_size, kernel_y1 + (y2 - y1))\n",
    "                kernel_x1 = max(0, half_size - (x - x1))\n",
    "                kernel_x2 = min(self.kernel_size, kernel_x1 + (x2 - x1))\n",
    "                \n",
    "                # Application du noyau gaussien\n",
    "                kernel_section = self.gaussian_kernel[\n",
    "                    kernel_y1:kernel_y2,\n",
    "                    kernel_x1:kernel_x2\n",
    "                ]\n",
    "                \n",
    "                self.grid_times[row, col] *= 1.01  # Petit bonus pour la cellule active\n",
    "\n",
    "    def overlay_heatmap(self, frame, alpha=0.5):\n",
    "        \"\"\"Superpose la heatmap sur l'image.\"\"\"\n",
    "        if frame is None:\n",
    "            return frame\n",
    "\n",
    "        with self.lock:\n",
    "            try:\n",
    "                output = frame.copy()\n",
    "                \n",
    "                if self.total_time > 0:\n",
    "                    # Calcul des pourcentages\n",
    "                    percentages = (self.grid_times / self.total_time) * 100\n",
    "                    \n",
    "                    # Création de la heatmap colorée\n",
    "                    heatmap_overlay = np.zeros((*frame.shape[:2], 3), dtype=np.uint8)\n",
    "                    \n",
    "                    for row in range(self.grid_rows):\n",
    "                        for col in range(self.grid_cols):\n",
    "                            if percentages[row, col] > 0:\n",
    "                                # Définition des limites de la cellule\n",
    "                                y1 = row * self.cell_height\n",
    "                                y2 = (row + 1) * self.cell_height\n",
    "                                x1 = col * self.cell_width\n",
    "                                x2 = (col + 1) * self.cell_width\n",
    "                                \n",
    "                                # Choix de la couleur basé sur le pourcentage\n",
    "                                normalized = percentages[row, col] / np.max(percentages)\n",
    "                                color_idx = int(np.clip(normalized * 255, 0, 255))\n",
    "                                color = self.color_gradient[color_idx]\n",
    "                                \n",
    "                                # Application de la couleur\n",
    "                                heatmap_overlay[y1:y2, x1:x2] = color\n",
    "                    \n",
    "                    # Fusion avec le frame\n",
    "                    mask = (heatmap_overlay > 0).any(axis=2)\n",
    "                    output[mask] = cv2.addWeighted(\n",
    "                        output[mask], 1-alpha,\n",
    "                        heatmap_overlay[mask], alpha,\n",
    "                        0\n",
    "                    )\n",
    "                    \n",
    "                    # Ajout de la grille et des pourcentages\n",
    "                    self._add_grid_overlay(output, percentages)\n",
    "                    \n",
    "                    # Ajout du temps total\n",
    "                    cv2.putText(output, f\"Temps total: {self.total_time:.1f}s\", \n",
    "                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                              (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                return output\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in overlay_heatmap: {e}\")\n",
    "                return frame.copy()\n",
    "\n",
    "    def _add_grid_overlay(self, frame, percentages):\n",
    "        \"\"\"Ajoute la grille et les pourcentages.\"\"\"\n",
    "        try:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = min(0.4, self.cell_width / 100)\n",
    "            \n",
    "            for row in range(self.grid_rows):\n",
    "                for col in range(self.grid_cols):\n",
    "                    # Dessin de la bordure de la cellule\n",
    "                    x1 = col * self.cell_width\n",
    "                    y1 = row * self.cell_height\n",
    "                    x2 = x1 + self.cell_width\n",
    "                    y2 = y1 + self.cell_height\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 1)\n",
    "                    \n",
    "                    # Ajout du pourcentage si significatif\n",
    "                    percentage = percentages[row, col]\n",
    "                    if percentage >= 0.5:  # Seuil de visibilité\n",
    "                        text = f\"{percentage:.1f}%\"\n",
    "                        (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, 1)\n",
    "                        text_x = x1 + (self.cell_width - text_w) // 2\n",
    "                        text_y = y1 + (self.cell_height + text_h) // 2\n",
    "                        \n",
    "                        # Texte avec contour pour meilleure lisibilité\n",
    "                        cv2.putText(frame, text, (int(text_x), int(text_y)), \n",
    "                                  font, font_scale, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "                        cv2.putText(frame, text, (int(text_x), int(text_y)), \n",
    "                                  font, font_scale, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in _add_grid_overlay: {e}\")\n",
    "\n",
    "    def save_final_visualization(self, output_path, frame):\n",
    "        \"\"\"Sauvegarde la visualisation finale.\"\"\"\n",
    "        if frame is None:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            final_frame = self.overlay_heatmap(frame.copy())\n",
    "            if final_frame is not None:\n",
    "                cv2.imwrite(output_path, final_frame)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2817d508-d765-4aca-bb9f-43970c2358fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration chargée avec succès\n",
      "Initialisation du traitement...\n",
      "Démarrage du traitement avec 15 threads...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb87f0f176f49678b511a8db1bed45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Traitement des frames:   0%|          | 0/1709 [00:00<?, ?frame/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance - FPS moyen: 10.96\n",
      "Heatmap finale sauvegardée : assets/LatestEyeTracking_final_heatmap.png\n",
      "\n",
      "Traitement terminé !\n",
      "Temps total : 175.49 secondes\n",
      "Frames traitées : 1709\n",
      "FPS moyen : 9.74\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import logging\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import time\n",
    "import subprocess\n",
    "import shutil\n",
    "import numba\n",
    "\n",
    "# Configuration des avertissements et du logging\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def process_frame_batch(data):\n",
    "    \"\"\"Traite une frame individuelle avec les données de suivi oculaire.\"\"\"\n",
    "    frame, coords, config, heatmap_visualizer, point_visualizer = data\n",
    "    \n",
    "    try:\n",
    "        if coords is not None:\n",
    "            # Application des visualisations\n",
    "            heatmap_visualizer.update_heatmap(coords)\n",
    "            processed_frame = point_visualizer.process_frame(frame, coords)\n",
    "            processed_frame = heatmap_visualizer.overlay_heatmap(processed_frame)\n",
    "            \n",
    "            # Affichage en temps réel\n",
    "            cv2.imshow('Eye Tracking Analysis', processed_frame)\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "            return processed_frame\n",
    "        else:\n",
    "            return frame.copy()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de traitement de frame : {e}\")\n",
    "        return frame.copy()\n",
    "\n",
    "def optimize_system_resources():\n",
    "    \"\"\"Optimise les ressources système pour le traitement.\"\"\"\n",
    "    try:\n",
    "        # Optimisation de la priorité du processus\n",
    "        p = psutil.Process(os.getpid())\n",
    "        if hasattr(p, \"nice\"):\n",
    "            p.nice(10)\n",
    "        \n",
    "        # Configuration du garbage collector\n",
    "        gc.enable()\n",
    "        gc.set_threshold(700, 10, 5)\n",
    "        \n",
    "        # Optimisations OpenCV\n",
    "        cv2.setNumThreads(multiprocessing.cpu_count())\n",
    "        \n",
    "        # Optimisations NumPy\n",
    "        np.set_printoptions(precision=3, suppress=True)\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur d'optimisation des ressources : {e}\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    # Application des optimisations système\n",
    "    optimize_system_resources()\n",
    "\n",
    "    # Chargement de la configuration\n",
    "    config = Config()\n",
    "    print(\"Configuration chargée avec succès\")\n",
    "    \n",
    "    # Création des processeurs avec un nombre optimal de threads\n",
    "    n_threads = max(1, multiprocessing.cpu_count() - 1)\n",
    "    video_processor = VideoProcessor(config)\n",
    "    data_processor = EyeTrackingDataProcessor(config)\n",
    "    \n",
    "    # Initialisation du traitement\n",
    "    print(\"Initialisation du traitement...\")\n",
    "    frame_count = video_processor.open_video()\n",
    "    data_processor.load_data()\n",
    "    data_processor.initialize_processing(frame_count)\n",
    "    \n",
    "    # Initialisation des visualiseurs (une seule instance pour toute la durée)\n",
    "    heatmap_visualizer = HeatmapVisualizer(video_processor.frame_size)\n",
    "    point_visualizer = PointVisualizer(config)\n",
    "    \n",
    "    # Variables de suivi\n",
    "    last_frame = None\n",
    "    frames_processed = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Démarrage du traitement avec {n_threads} threads...\")\n",
    "    \n",
    "    # Configuration de la fenêtre d'affichage\n",
    "    cv2.namedWindow('Eye Tracking Analysis', cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Traitement principal avec ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "        # Barre de progression pour Jupyter\n",
    "        for _ in tqdm(range(frame_count), desc=\"Traitement des frames\", unit=\"frame\"):\n",
    "            # Lecture de la frame\n",
    "            ret, frame = video_processor.read_frame()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Obtention des coordonnées\n",
    "            coords = data_processor.get_coordinates(video_processor.frame_size)\n",
    "            \n",
    "            # Traitement de la frame\n",
    "            processed_frame = process_frame_batch((\n",
    "                frame, coords, config, heatmap_visualizer, point_visualizer\n",
    "            ))\n",
    "            \n",
    "            # Mise à jour et sauvegarde\n",
    "            if processed_frame is not None:\n",
    "                last_frame = processed_frame.copy()\n",
    "                video_processor.write_frame(processed_frame)\n",
    "                frames_processed += 1\n",
    "            \n",
    "            # Nettoyage périodique de la mémoire\n",
    "            if frames_processed % 100 == 0:\n",
    "                gc.collect()\n",
    "                # Affichage des stats de performance\n",
    "                elapsed_time = time.time() - start_time\n",
    "                fps = frames_processed / elapsed_time if elapsed_time > 0 else 0\n",
    "                print(f\"\\rPerformance - FPS moyen: {fps:.2f}\", end='')\n",
    "    \n",
    "    # Sauvegarde de la visualisation finale\n",
    "    if last_frame is not None:\n",
    "        final_output = os.path.splitext(config.output_path)[0] + \"_final_heatmap.png\"\n",
    "        heatmap_visualizer.save_final_visualization(final_output, last_frame)\n",
    "        print(f\"\\nHeatmap finale sauvegardée : {final_output}\")\n",
    "    \n",
    "    # Nettoyage et finalisation\n",
    "    video_processor.release()\n",
    "    \n",
    "    # Statistiques finales\n",
    "    total_time = time.time() - start_time\n",
    "    average_fps = frames_processed / total_time if total_time > 0 else 0\n",
    "    print(f\"\\nTraitement terminé !\")\n",
    "    print(f\"Temps total : {total_time:.2f} secondes\")\n",
    "    print(f\"Frames traitées : {frames_processed}\")\n",
    "    print(f\"FPS moyen : {average_fps:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du traitement : {str(e)}\")\n",
    "    raise e\n",
    "finally:\n",
    "    # Attendre un peu avant de fermer les fenêtres\n",
    "    cv2.waitKey(1000)\n",
    "    cv2.destroyAllWindows()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37925fee-c8ec-41b4-bdc2-593cb9b6a85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
